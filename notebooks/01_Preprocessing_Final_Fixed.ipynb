{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Real-Time Clustering (FIXED - No Data Leakage)\n",
    "\n",
    "**CRITICAL FIX**: This notebook eliminates data leakage by using only PREVIOUS questions' data.\n",
    "\n",
    "**What Changed**:\n",
    "- Cumulative metrics calculated BEFORE processing current question\n",
    "- Removed `is_correct` from features (that's the target!)\n",
    "- Renamed features to clarify they're from previous questions\n",
    "\n",
    "**Expected Results**: Realistic 75-85% accuracy (not 99.71%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main dataset\n",
    "df = pd.read_csv('/content/drive/MyDrive/FYP_Data/Merge_Enhanced_Fixed.csv')\n",
    "print(f\"üìä Loaded {len(df)} records\")\n",
    "print(f\"   Students: {df['Admission No'].nunique()}\")\n",
    "\n",
    "# Load participant tracking\n",
    "participant_df = pd.read_csv('/content/drive/MyDrive/FYP_Data/Participant_Tracking.csv')\n",
    "print(f\"\\nüìä Loaded {len(participant_df)} participant events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Filter Participating Students Only\n",
    "\n",
    "**Why**: Only cluster students who joined the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get students who joined sessions\n",
    "participated_students = participant_df[\n",
    "    participant_df['Event Type'] == 'Joined'\n",
    "]['Admission No'].unique()\n",
    "\n",
    "print(f\"üë• Students who participated: {len(participated_students)}\")\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df[df['Admission No'].isin(participated_students)].copy()\n",
    "print(f\"‚úÖ Filtered to {len(df_filtered)} records from participating students\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Separate Initial Questions from Regular Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate by Quiz#\n",
    "df_initial = df_filtered[df_filtered['Quiz#'] == 0].copy()\n",
    "df_regular = df_filtered[df_filtered['Quiz#'] != 0].copy()\n",
    "\n",
    "print(f\"üìã Initial questions (Quiz# = 0): {len(df_initial)} records\")\n",
    "print(f\"   Should be 1 per student: {df_initial['Admission No'].nunique()} students\")\n",
    "print(f\"\\nüìã Regular questions: {len(df_regular)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: **CRITICAL FIX** - Dynamic Cluster Assignment (No Leakage)\n",
    "\n",
    "**The Fix**: Calculate metrics using ONLY previous questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_cluster(prev_accuracy, prev_avg_time, has_network_issue):\n",
    "    \"\"\"\n",
    "    Assign cluster based on PREVIOUS performance only\n",
    "    \n",
    "    Parameters:\n",
    "    - prev_accuracy: Accuracy on Q1 to Q(n-1) [0.0 to 1.0]\n",
    "    - prev_avg_time: Avg response time on Q1 to Q(n-1) [seconds]\n",
    "    - has_network_issue: Boolean indicating network problems\n",
    "    \n",
    "    Returns:\n",
    "    - cluster: 'Active', 'Moderate', or 'Passive'\n",
    "    \"\"\"\n",
    "    # Network issue ‚Üí Passive (can't perform well with bad connection)\n",
    "    if has_network_issue:\n",
    "        return 'Passive'\n",
    "    \n",
    "    # High accuracy + Fast response ‚Üí Active\n",
    "    if prev_accuracy > 0.80 and prev_avg_time < 30:\n",
    "        return 'Active'\n",
    "    \n",
    "    # Medium accuracy + Reasonable response ‚Üí Moderate\n",
    "    elif prev_accuracy > 0.50 and prev_avg_time < 60:\n",
    "        return 'Moderate'\n",
    "    \n",
    "    # Everything else ‚Üí Passive\n",
    "    else:\n",
    "        return 'Passive'\n",
    "\n",
    "print(\"‚úÖ Cluster assignment function defined (uses previous data only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Process Regular Questions (FIXED - No Leakage)\n",
    "\n",
    "**CRITICAL**: Metrics calculated BEFORE processing current question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by student and timestamp (chronological order)\n",
    "df_regular_sorted = df_regular.sort_values(['Admission No', 'Timestamp']).copy()\n",
    "\n",
    "# Lists to store processed data\n",
    "completed_data = []\n",
    "not_completed_data = []\n",
    "\n",
    "# Process each student\n",
    "for student_id in df_regular_sorted['Admission No'].unique():\n",
    "    student_questions = df_regular_sorted[df_regular_sorted['Admission No'] == student_id]\n",
    "    \n",
    "    # Initialize counters (for tracking previous performance)\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    response_times = []\n",
    "    \n",
    "    # Process each question chronologically\n",
    "    for idx, row in student_questions.iterrows():\n",
    "        \n",
    "        # ========== CRITICAL: Calculate from PREVIOUS questions ONLY ==========\n",
    "        if total_count > 0:\n",
    "            # Have previous data\n",
    "            prev_accuracy = correct_count / total_count  # Q1 to Q(n-1) only!\n",
    "            prev_avg_time = np.mean(response_times)      # Q1 to Q(n-1) only!\n",
    "        else:\n",
    "            # First question: use defaults\n",
    "            prev_accuracy = 0.0\n",
    "            prev_avg_time = 0.0\n",
    "        \n",
    "        # Check network quality\n",
    "        has_network_issue = (\n",
    "            row['RTT'] > 1000 or \n",
    "            row['Jitter'] > 500 or \n",
    "            row['Stability'] < 80\n",
    "        )\n",
    "        \n",
    "        # Assign cluster based on PREVIOUS performance\n",
    "        cluster = assign_cluster(prev_accuracy, prev_avg_time, has_network_issue)\n",
    "        \n",
    "        # Create feature dict (NO is_correct - that's the target!)\n",
    "        if row['Attempt Status'] == 'Completed':\n",
    "            features = {\n",
    "                'student_id': student_id,\n",
    "                'prev_accuracy': prev_accuracy,           # ‚úÖ From Q1 to Q(n-1)\n",
    "                'prev_avg_time': prev_avg_time,           # ‚úÖ From Q1 to Q(n-1)\n",
    "                'total_questions_so_far': total_count,    # ‚úÖ Count before current\n",
    "                'current_response_time': row['Response Time'],  # ‚úÖ Available\n",
    "                'cluster': cluster  # Label to predict\n",
    "            }\n",
    "            completed_data.append(features)\n",
    "        else:\n",
    "            # Not completed: include network params\n",
    "            features = {\n",
    "                'student_id': student_id,\n",
    "                'prev_accuracy': prev_accuracy,\n",
    "                'prev_avg_time': prev_avg_time,\n",
    "                'total_questions_so_far': total_count,\n",
    "                'current_response_time': row['Response Time'],\n",
    "                'rtt': row['RTT'],\n",
    "                'jitter': row['Jitter'],\n",
    "                'stability': row['Stability'],\n",
    "                'cluster': cluster\n",
    "            }\n",
    "            not_completed_data.append(features)\n",
    "        \n",
    "        # ========== NOW update counters for NEXT iteration ==========\n",
    "        if row['Attempt Status'] == 'Completed':\n",
    "            correct_count += row['Is_Correct']\n",
    "            total_count += 1\n",
    "            response_times.append(row['Response Time'])\n",
    "\n",
    "print(f\"‚úÖ Processed {len(completed_data)} completed questions\")\n",
    "print(f\"‚úÖ Processed {len(not_completed_data)} not completed questions\")\n",
    "print(f\"\\nüéØ KEY FIX: Features use ONLY previous questions' data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create DataFrames and Check Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrames\n",
    "df_completed = pd.DataFrame(completed_data)\n",
    "df_not_completed = pd.DataFrame(not_completed_data)\n",
    "\n",
    "# Check cluster distribution\n",
    "print(\"üìä Cluster Distribution (Completed):\")\n",
    "print(df_completed['cluster'].value_counts())\n",
    "print(f\"\\n{df_completed['cluster'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüìã Sample Features (NO is_correct in features!):\")\n",
    "print(df_completed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Prepare Initial Question Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For K-Means initial clustering\n",
    "X_initial = df_initial[['Response Time', 'RTT', 'Jitter', 'Stability']].values\n",
    "y_initial = df_initial['Engagement Level'].values\n",
    "\n",
    "print(f\"‚úÖ Initial question features: {X_initial.shape}\")\n",
    "print(f\"   Features: Response Time, RTT, Jitter, Stability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Prepare Completed Question Features (NEW - No Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: prev_accuracy, prev_avg_time, total_questions_so_far, current_response_time\n",
    "# Label: cluster\n",
    "\n",
    "feature_cols_completed = ['prev_accuracy', 'prev_avg_time', 'total_questions_so_far', 'current_response_time']\n",
    "X_completed = df_completed[feature_cols_completed].values\n",
    "y_completed = df_completed['cluster'].values\n",
    "\n",
    "print(f\"‚úÖ Completed question features: {X_completed.shape}\")\n",
    "print(f\"   Features: {feature_cols_completed}\")\n",
    "print(f\"   ‚ö†Ô∏è NOTE: is_correct REMOVED (that's what we predict!)\")\n",
    "print(f\"\\n   Labels: {y_completed.shape} clusters to predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Prepare Not Completed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_not_completed) > 0:\n",
    "    feature_cols_not_completed = [\n",
    "        'prev_accuracy', 'prev_avg_time', 'total_questions_so_far', \n",
    "        'current_response_time', 'rtt', 'jitter', 'stability'\n",
    "    ]\n",
    "    X_not_completed = df_not_completed[feature_cols_not_completed].values\n",
    "    y_not_completed = df_not_completed['cluster'].values\n",
    "    \n",
    "    print(f\"‚úÖ Not completed features: {X_not_completed.shape}\")\n",
    "    print(f\"   Features: {feature_cols_not_completed}\")\n",
    "else:\n",
    "    X_not_completed = np.array([])\n",
    "    y_not_completed = np.array([])\n",
    "    print(\"‚ÑπÔ∏è No not-completed questions in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale initial question features\n",
    "scaler_initial = StandardScaler()\n",
    "X_initial_scaled = scaler_initial.fit_transform(X_initial)\n",
    "\n",
    "# Scale completed question features\n",
    "scaler_completed = StandardScaler()\n",
    "X_completed_scaled = scaler_completed.fit_transform(X_completed)\n",
    "\n",
    "# Scale not completed if exists\n",
    "if len(X_not_completed) > 0:\n",
    "    scaler_not_completed = StandardScaler()\n",
    "    X_not_completed_scaled = scaler_not_completed.fit_transform(X_not_completed)\n",
    "else:\n",
    "    scaler_not_completed = None\n",
    "    X_not_completed_scaled = np.array([])\n",
    "\n",
    "print(\"‚úÖ All features scaled (mean=0, std=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = '/content/drive/MyDrive/FYP_Data/Preprocessed_Fixed'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save everything\n",
    "np.save(f'{output_dir}/X_initial_scaled.npy', X_initial_scaled)\n",
    "np.save(f'{output_dir}/y_initial.npy', y_initial)\n",
    "\n",
    "np.save(f'{output_dir}/X_completed_scaled.npy', X_completed_scaled)\n",
    "np.save(f'{output_dir}/y_completed.npy', y_completed)\n",
    "\n",
    "if len(X_not_completed_scaled) > 0:\n",
    "    np.save(f'{output_dir}/X_not_completed_scaled.npy', X_not_completed_scaled)\n",
    "    np.save(f'{output_dir}/y_not_completed.npy', y_not_completed)\n",
    "\n",
    "# Save scalers\n",
    "with open(f'{output_dir}/scaler_initial.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_initial, f)\n",
    "\n",
    "with open(f'{output_dir}/scaler_completed.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_completed, f)\n",
    "\n",
    "if scaler_not_completed:\n",
    "    with open(f'{output_dir}/scaler_not_completed.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_not_completed, f)\n",
    "\n",
    "# Save feature names\n",
    "feature_info = {\n",
    "    'completed_features': feature_cols_completed,\n",
    "    'not_completed_features': feature_cols_not_completed if len(df_not_completed) > 0 else [],\n",
    "    'note': 'is_correct REMOVED to prevent data leakage'\n",
    "}\n",
    "\n",
    "with open(f'{output_dir}/feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "\n",
    "print(f\"‚úÖ All files saved to {output_dir}\")\n",
    "print(f\"\\nüìÅ Files created:\")\n",
    "print(f\"   - X_initial_scaled.npy\")\n",
    "print(f\"   - y_initial.npy\")\n",
    "print(f\"   - X_completed_scaled.npy\")\n",
    "print(f\"   - y_completed.npy\")\n",
    "print(f\"   - X_not_completed_scaled.npy (if applicable)\")\n",
    "print(f\"   - y_not_completed.npy (if applicable)\")\n",
    "print(f\"   - scaler_initial.pkl\")\n",
    "print(f\"   - scaler_completed.pkl\")\n",
    "print(f\"   - scaler_not_completed.pkl (if applicable)\")\n",
    "print(f\"   - feature_names.pkl\")\n",
    "print(f\"\\nüéØ Data is ready for model training (NO LEAKAGE!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What Was Fixed:\n",
    "\n",
    "1. ‚úÖ **Cumulative metrics** calculated BEFORE processing current question\n",
    "2. ‚úÖ **Removed is_correct** from features (that's the target!)\n",
    "3. ‚úÖ **Renamed features** to clarify temporal ordering:\n",
    "   - `cumulative_accuracy` ‚Üí `prev_accuracy`\n",
    "   - `avg_response_time` ‚Üí `prev_avg_time`\n",
    "   - `total_questions` ‚Üí `total_questions_so_far`\n",
    "4. ‚úÖ **Proper first-question handling** (defaults to 0.0)\n",
    "5. ‚úÖ **Update counters AFTER** creating training sample\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "- **Accuracy**: 75-85% (realistic, not 99.71%)\n",
    "- **Model**: Learns engagement patterns, not memorizes answers\n",
    "- **Production**: Works with real-time constraints\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Run **02_Model_Training_RealTime_Fixed.ipynb** to train models\n",
    "2. Verify accuracy is in 75-85% range (not 99.71%)\n",
    "3. Use **03_RealTime_Inference_Demo_Fixed.ipynb** for deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
