{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Predictive Clustering + Engagement Prediction\n",
    "\n",
    "**Objectives**:\n",
    "1. **Part A - Clustering (K-Means)**: Real-time student engagement clustering\n",
    "2. **Part B - Prediction (Random Forest)**: Engagement level prediction\n",
    "\n",
    "**Prerequisites**: Run `01_Preprocessing_Enhanced_Dataset.ipynb` first\n",
    "\n",
    "**Evaluation**:\n",
    "- Clustering: Silhouette Score, Davies-Bouldin Index, Calinski-Harabasz\n",
    "- Classification: Accuracy, Precision, Recall, F1-Score, ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn xgboost imbalanced-learn -q\n",
    "print(\"‚úÖ Packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Drive mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, davies_bouldin_score, calinski_harabasz_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to preprocessed data\n",
    "DATA_PATH = '/content/drive/MyDrive/FYP_Data/Preprocessed/'\n",
    "\n",
    "# Load initial questions data\n",
    "X_initial = np.load(DATA_PATH + 'X_initial_scaled.npy')\n",
    "y_initial = np.load(DATA_PATH + 'y_initial.npy')\n",
    "\n",
    "# Load completed questions data\n",
    "X_completed = np.load(DATA_PATH + 'X_completed_scaled.npy')\n",
    "y_completed = np.load(DATA_PATH + 'y_completed.npy')\n",
    "\n",
    "# Load not completed questions data\n",
    "X_not_completed = np.load(DATA_PATH + 'X_not_completed_scaled.npy')\n",
    "y_not_completed = np.load(DATA_PATH + 'y_not_completed.npy')\n",
    "\n",
    "# Load scalers\n",
    "with open(DATA_PATH + 'scaler_initial.pkl', 'rb') as f:\n",
    "    scaler_initial = pickle.load(f)\n",
    "with open(DATA_PATH + 'scaler_completed.pkl', 'rb') as f:\n",
    "    scaler_completed = pickle.load(f)\n",
    "\n",
    "print(\"‚úÖ Data loaded\")\n",
    "print(f\"\\nInitial Questions: {X_initial.shape}\")\n",
    "print(f\"Completed Questions: {X_completed.shape}\")\n",
    "print(f\"Not Completed Questions: {X_not_completed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Elbow Method for Optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method on initial questions\n",
    "print(\"Performing Elbow Method...\")\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, random_state=42)\n",
    "    kmeans.fit(X_initial)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    print(f\"K={k}: Inertia={kmeans.inertia_:.2f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (K)', fontsize=12)\n",
    "plt.ylabel('Inertia (WCSS)', fontsize=12)\n",
    "plt.title('Elbow Method for Optimal K', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(K_range)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Optimal K appears to be around 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train K-Means Model (K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Means with K=3\n",
    "print(\"Training K-Means Clustering Model (K=3)...\")\n",
    "kmeans = KMeans(\n",
    "    n_clusters=3,\n",
    "    init='k-means++',\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on initial questions\n",
    "cluster_labels = kmeans.fit_predict(X_initial)\n",
    "\n",
    "print(f\"\\n‚úÖ Model trained\")\n",
    "print(f\"Cluster distribution: {np.bincount(cluster_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Map Clusters to Engagement Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map cluster IDs to engagement levels based on characteristics\n",
    "cluster_means = {}\n",
    "for i in range(3):\n",
    "    cluster_data = X_initial[cluster_labels == i]\n",
    "    engagement_score = cluster_data.mean(axis=0).mean()\n",
    "    cluster_means[i] = engagement_score\n",
    "    print(f\"Cluster {i}: Mean Score = {engagement_score:.3f}\")\n",
    "\n",
    "# Sort and map: lowest ‚Üí Passive, middle ‚Üí Moderate, highest ‚Üí Active\n",
    "sorted_clusters = sorted(cluster_means.items(), key=lambda x: x[1])\n",
    "cluster_mapping = {\n",
    "    sorted_clusters[0][0]: 0,  # Passive\n",
    "    sorted_clusters[1][0]: 1,  # Moderate\n",
    "    sorted_clusters[2][0]: 2   # Active\n",
    "}\n",
    "\n",
    "mapped_labels = np.array([cluster_mapping[label] for label in cluster_labels])\n",
    "cluster_names = {0: 'Passive', 1: 'Moderate', 2: 'Active'}\n",
    "\n",
    "print(\"\\n‚úÖ Clusters mapped to engagement levels\")\n",
    "for i in range(3):\n",
    "    count = (mapped_labels == i).sum()\n",
    "    print(f\"{cluster_names[i]}: {count} ({count/len(mapped_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate Clustering Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "silhouette = silhouette_score(X_initial, mapped_labels)\n",
    "davies_bouldin = davies_bouldin_score(X_initial, mapped_labels)\n",
    "calinski = calinski_harabasz_score(X_initial, mapped_labels)\n",
    "\n",
    "print(\"Clustering Quality Metrics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Silhouette Score:        {silhouette:.4f}\")\n",
    "print(f\"Davies-Bouldin Index:    {davies_bouldin:.4f}\")\n",
    "print(f\"Calinski-Harabasz:       {calinski:.4f}\")\n",
    "print(f\"Inertia (WCSS):          {kmeans.inertia_:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if silhouette > 0.5:\n",
    "    print(f\"‚úÖ Silhouette ({silhouette:.3f}): Excellent clustering\")\n",
    "elif silhouette > 0.3:\n",
    "    print(f\"‚úÖ Silhouette ({silhouette:.3f}): Good clustering\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Silhouette ({silhouette:.3f}): Weak clustering\")\n",
    "\n",
    "if davies_bouldin < 1.0:\n",
    "    print(f\"‚úÖ Davies-Bouldin ({davies_bouldin:.3f}): Excellent separation\")\n",
    "elif davies_bouldin < 2.0:\n",
    "    print(f\"‚úÖ Davies-Bouldin ({davies_bouldin:.3f}): Good separation\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Davies-Bouldin ({davies_bouldin:.3f}): Poor separation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize Clusters with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for 2D visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_initial)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['#FF6B6B', '#FFD93D', '#6BCB77']  # Red, Yellow, Green\n",
    "\n",
    "for i in range(3):\n",
    "    mask = mapped_labels == i\n",
    "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
    "               c=colors[i], label=cluster_names[i],\n",
    "               alpha=0.6, s=100, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Plot centroids\n",
    "centroids_pca = pca.transform(kmeans.cluster_centers_)\n",
    "plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1],\n",
    "           c='black', marker='X', s=300,\n",
    "           edgecolors='white', linewidth=2,\n",
    "           label='Centroids', zorder=10)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
    "plt.title('Student Engagement Clusters (K-Means)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save Clustering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and mapping\n",
    "MODEL_PATH = '/content/drive/MyDrive/FYP_Data/Models/'\n",
    "!mkdir -p \"$MODEL_PATH\"\n",
    "\n",
    "with open(MODEL_PATH + 'kmeans_model.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "\n",
    "with open(MODEL_PATH + 'cluster_mapping.pkl', 'wb') as f:\n",
    "    pickle.dump(cluster_mapping, f)\n",
    "\n",
    "print(\"‚úÖ Clustering model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Engagement Prediction (Supervised Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use completed questions for supervised learning\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_completed, y_completed,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y_completed\n",
    ")\n",
    "\n",
    "print(\"Data Split:\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "print(\"\\nClass distribution in training:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  {cluster_names[label]}: {count} ({count/len(y_train)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Handle Class Imbalance with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance classes\n",
    "print(\"Applying SMOTE to balance classes...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBefore SMOTE: {X_train.shape}\")\n",
    "print(f\"After SMOTE: {X_train_balanced.shape}\")\n",
    "\n",
    "print(\"\\nBalanced class distribution:\")\n",
    "unique, counts = np.unique(y_train_balanced, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  {cluster_names[label]}: {count} ({count/len(y_train_balanced)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_balanced, y_train_balanced)\n",
    "print(\"‚úÖ Model trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "print(\"Random Forest Performance:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf,\n",
    "                          target_names=['Passive', 'Moderate', 'Active']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=['Passive', 'Moderate', 'Active'],\n",
    "           yticklabels=['Passive', 'Moderate', 'Active'])\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.title('Confusion Matrix - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train XGBoost (Alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"Training XGBoost Classifier...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "print(\"‚úÖ XGBoost trained\")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "\n",
    "print(f\"\\nXGBoost Performance:\")\n",
    "print(f\"Accuracy:  {accuracy_xgb:.4f}\")\n",
    "print(f\"F1-Score:  {f1_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [accuracy, accuracy_xgb],\n",
    "    'F1-Score': [f1, f1_xgb]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Choose best model\n",
    "best_model_name = 'Random Forest' if accuracy >= accuracy_xgb else 'XGBoost'\n",
    "best_model = rf_model if accuracy >= accuracy_xgb else xgb_model\n",
    "print(f\"\\n‚úÖ Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation\n",
    "print(\"Performing 5-fold cross-validation...\")\n",
    "cv_scores = cross_val_score(best_model, X_train_balanced, y_train_balanced,\n",
    "                           cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nCV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "with open(MODEL_PATH + 'random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "with open(MODEL_PATH + 'xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "\n",
    "print(\"‚úÖ Prediction models saved to:\")\n",
    "print(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\" \"*25 + \"MODEL TRAINING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä CLUSTERING (K-Means):\")\n",
    "print(f\"  Silhouette Score:     {silhouette:.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {davies_bouldin:.4f}\")\n",
    "print(f\"  Number of Clusters:   3\")\n",
    "\n",
    "print(\"\\nüéØ CLASSIFICATION (Random Forest):\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\nüíæ SAVED MODELS:\")\n",
    "print(f\"  ‚úÖ kmeans_model.pkl\")\n",
    "print(f\"  ‚úÖ random_forest_model.pkl\")\n",
    "print(f\"  ‚úÖ xgboost_model.pkl\")\n",
    "print(f\"  ‚úÖ cluster_mapping.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Model training complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
