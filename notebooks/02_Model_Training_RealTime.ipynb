{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for Real-Time Clustering\n",
    "\n",
    "This notebook trains two models for real-time student engagement clustering:\n",
    "\n",
    "1. **K-Means**: Initial clustering from first question\n",
    "2. **Random Forest**: Dynamic cluster updates during session\n",
    "\n",
    "**Prerequisites**: Run `01_Preprocessing_Final.ipynb` first to generate training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/content/drive/MyDrive/FYP_Data/Preprocessed'\n",
    "\n",
    "# Load initial question data\n",
    "X_initial = np.load(f'{data_dir}/X_initial_scaled.npy')\n",
    "y_initial = np.load(f'{data_dir}/y_initial.npy')\n",
    "\n",
    "# Load completed question data\n",
    "X_completed = np.load(f'{data_dir}/X_completed_scaled.npy')\n",
    "y_completed = np.load(f'{data_dir}/y_completed.npy')\n",
    "\n",
    "# Load not completed question data\n",
    "X_not_completed = np.load(f'{data_dir}/X_not_completed_scaled.npy')\n",
    "y_not_completed = np.load(f'{data_dir}/y_not_completed.npy')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"\\nInitial questions: {X_initial.shape[0]} samples, {X_initial.shape[1]} features\")\n",
    "print(f\"Completed questions: {X_completed.shape[0]} samples, {X_completed.shape[1]} features\")\n",
    "print(f\"Not completed questions: {X_not_completed.shape[0]} samples, {X_not_completed.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train K-Means for Initial Clustering\n",
    "\n",
    "K-Means provides quick baseline clustering when students first join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Means with k=3 (Passive, Moderate, Active)\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X_initial)\n",
    "\n",
    "# Evaluate clustering quality\n",
    "silhouette = silhouette_score(X_initial, kmeans_labels)\n",
    "davies_bouldin = davies_bouldin_score(X_initial, kmeans_labels)\n",
    "calinski = calinski_harabasz_score(X_initial, kmeans_labels)\n",
    "\n",
    "print(\"K-Means Clustering Results:\")\n",
    "print(f\"  Silhouette Score: {silhouette:.4f} (higher is better, >0.4 is good)\")\n",
    "print(f\"  Davies-Bouldin Index: {davies_bouldin:.4f} (lower is better, <1.0 is good)\")\n",
    "print(f\"  Calinski-Harabasz Score: {calinski:.2f} (higher is better)\")\n",
    "\n",
    "# Map clusters to engagement levels based on characteristics\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "# Assuming feature 0 is response time (lower is better)\n",
    "cluster_scores = -cluster_centers[:, 0]  # Negate so lower time = higher score\n",
    "cluster_order = np.argsort(cluster_scores)  # Sort by score\n",
    "\n",
    "cluster_mapping = {\n",
    "    cluster_order[0]: 'Passive',\n",
    "    cluster_order[1]: 'Moderate',\n",
    "    cluster_order[2]: 'Active'\n",
    "}\n",
    "\n",
    "print(f\"\\nCluster Mapping: {cluster_mapping}\")\n",
    "\n",
    "# Apply mapping\n",
    "kmeans_mapped_labels = [cluster_mapping[label] for label in kmeans_labels]\n",
    "print(f\"\\nCluster Distribution:\")\n",
    "unique, counts = np.unique(kmeans_mapped_labels, return_counts=True)\n",
    "for eng_level, count in zip(unique, counts):\n",
    "    print(f\"  {eng_level}: {count} ({count/len(kmeans_mapped_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Combine Data for Dynamic Clustering Model\n",
    "\n",
    "Merge completed and not-completed questions for comprehensive training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For not completed, we need to match feature dimensions with completed\n",
    "# We'll use the first 5 features which are common\n",
    "X_not_completed_reduced = X_not_completed[:, :5]\n",
    "\n",
    "# Combine datasets\n",
    "X_combined = np.vstack([X_completed, X_not_completed_reduced])\n",
    "y_combined = np.concatenate([y_completed, y_not_completed])\n",
    "\n",
    "print(f\"Combined training data: {X_combined.shape[0]} samples\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "unique, counts = np.unique(y_combined, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  {label}: {count} ({count/len(y_combined)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Random Forest for Dynamic Updates\n",
    "\n",
    "Random Forest learns patterns and predicts cluster updates in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y_combined, test_size=0.2, random_state=42, stratify=y_combined\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"âœ… Training complete!\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\nðŸ“Š Random Forest Performance:\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "print(f\"  F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation\n",
    "cv_scores = cross_val_score(rf_model, X_combined, y_combined, cv=5, scoring='f1_weighted')\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "print(f\"  Mean F1-Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "print(f\"  Individual Folds: {cv_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['Passive', 'Moderate', 'Active'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Passive', 'Moderate', 'Active'],\n",
    "            yticklabels=['Passive', 'Moderate', 'Active'])\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/FYP_Data/Models/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Confusion matrix saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_names = ['Cumulative Accuracy', 'Avg Response Time', 'Total Questions', 'Current Response Time', 'Is Correct']\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, importances)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance - Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/FYP_Data/Models/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Feature Importance:\")\n",
    "for name, importance in zip(feature_names, importances):\n",
    "    print(f\"  {name}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory\n",
    "models_dir = '/content/drive/MyDrive/FYP_Data/Models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save K-Means\n",
    "joblib.dump(kmeans, f'{models_dir}/kmeans_initial.pkl')\n",
    "joblib.dump(cluster_mapping, f'{models_dir}/cluster_mapping.pkl')\n",
    "\n",
    "# Save Random Forest\n",
    "joblib.dump(rf_model, f'{models_dir}/rf_dynamic.pkl')\n",
    "\n",
    "# Load scalers and save to models directory\n",
    "with open(f'{data_dir}/scaler_initial.pkl', 'rb') as f:\n",
    "    scaler_initial = pickle.load(f)\n",
    "with open(f'{data_dir}/scaler_completed.pkl', 'rb') as f:\n",
    "    scaler_completed = pickle.load(f)\n",
    "\n",
    "joblib.dump(scaler_initial, f'{models_dir}/scaler_initial.pkl')\n",
    "joblib.dump(scaler_completed, f'{models_dir}/scaler_dynamic.pkl')\n",
    "\n",
    "print(\"\\nâœ… All models saved successfully!\")\n",
    "print(f\"\\nSaved files:\")\n",
    "print(f\"  - kmeans_initial.pkl\")\n",
    "print(f\"  - cluster_mapping.pkl\")\n",
    "print(f\"  - rf_dynamic.pkl\")\n",
    "print(f\"  - scaler_initial.pkl\")\n",
    "print(f\"  - scaler_dynamic.pkl\")\n",
    "print(f\"  - confusion_matrix.png\")\n",
    "print(f\"  - feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Training Complete!**\n",
    "\n",
    "**Model 1 - K-Means (Initial Clustering)**:\n",
    "- Silhouette Score: {silhouette:.4f}\n",
    "- Davies-Bouldin Index: {davies_bouldin:.4f}\n",
    "- Purpose: Quick baseline classification from initial question\n",
    "\n",
    "**Model 2 - Random Forest (Dynamic Updates)**:\n",
    "- Accuracy: {accuracy:.4f}\n",
    "- F1-Score: {f1:.4f}\n",
    "- Cross-Validation: {cv_scores.mean():.4f}\n",
    "- Purpose: Real-time cluster updates during session\n",
    "\n",
    "**Next Step**: Use `03_RealTime_Inference_Demo.ipynb` to see real-time clustering in action!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
